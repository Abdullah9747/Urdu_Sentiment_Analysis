{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Phase 1 - Data Collection and Data Preprocessing",
   "id": "8ebc4d05c0bdd166"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-28T19:29:22.089349Z",
     "start_time": "2024-09-28T19:29:22.084958Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# from idlelib.editor import darwin\n",
    "# !pip install pandas"
   ],
   "id": "7ef284cc38d52eb6",
   "outputs": [],
   "execution_count": 558
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Data Loading",
   "id": "fd4ed1f4415ae203"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-28T19:29:22.169770Z",
     "start_time": "2024-09-28T19:29:22.149708Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from nltk import bigrams\n",
    "\n",
    "file_path = 'urdu-sentiment-corpus-v1.tsv'\n",
    "data = pd.read_csv(file_path, sep='\\t')\n",
    "data.head()\n"
   ],
   "id": "b354e26daef74328",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                               Tweet Class\n",
       "0  میں نے ایٹم بم بنایا ھے ۔۔۔۔او بھائی ایٹم بمب ...     P\n",
       "1  چندے سے انقلاب اور عمران خان وزیر اعظم نہیں بن...     N\n",
       "2                           ٹویٹر کا خیال کیسے آیا ؟     O\n",
       "3  سرچ انجن گوگل کے نائب صدر نے فضا میں ، 130,000...     P\n",
       "4    ابھی تک اسکی لہریں کبھی کبھی آ جاتی ہیں یار :أْ     P"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>میں نے ایٹم بم بنایا ھے ۔۔۔۔او بھائی ایٹم بمب ...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>چندے سے انقلاب اور عمران خان وزیر اعظم نہیں بن...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ٹویٹر کا خیال کیسے آیا ؟</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>سرچ انجن گوگل کے نائب صدر نے فضا میں ، 130,000...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ابھی تک اسکی لہریں کبھی کبھی آ جاتی ہیں یار :أْ</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 559,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 559
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Loading Stop Words",
   "id": "9ef88dcc692b209a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-28T19:29:22.306011Z",
     "start_time": "2024-09-28T19:29:22.291132Z"
    }
   },
   "cell_type": "code",
   "source": [
    "stopWords=[]\n",
    "with open('urdu_stopwords.txt', 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        stopWords.append(line.strip()) # used strip to remove leading and trailing white spaces\n",
    "stopWords\n"
   ],
   "id": "5ed11ca187915131",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['آئی',\n",
       " 'آئے',\n",
       " 'آج',\n",
       " 'آخر',\n",
       " 'آخرکبر',\n",
       " 'آدهی',\n",
       " 'آًب',\n",
       " 'آٹھ',\n",
       " 'آیب',\n",
       " 'اة',\n",
       " 'اخبزت',\n",
       " 'اختتبم',\n",
       " 'ادھر',\n",
       " 'ارد',\n",
       " 'اردگرد',\n",
       " 'ارکبى',\n",
       " 'اش',\n",
       " 'اضتعوبل',\n",
       " 'اضتعوبلات',\n",
       " 'اضطرذ',\n",
       " 'اضکب',\n",
       " 'اضکی',\n",
       " 'اضکے',\n",
       " 'اطراف',\n",
       " 'اغیب',\n",
       " 'افراد',\n",
       " 'الگ',\n",
       " 'اور',\n",
       " 'اوًچب',\n",
       " 'اوًچبئی',\n",
       " 'اوًچی',\n",
       " 'اوًچے',\n",
       " 'اى',\n",
       " 'اً',\n",
       " 'اًذر',\n",
       " 'اًہیں',\n",
       " 'اٹھبًب',\n",
       " 'اپٌب',\n",
       " 'اپٌے',\n",
       " 'اچھب',\n",
       " 'اچھی',\n",
       " 'اچھے',\n",
       " 'اکثر',\n",
       " 'اکٹھب',\n",
       " 'اکٹھی',\n",
       " 'اکٹھے',\n",
       " 'اکیلا',\n",
       " 'اکیلی',\n",
       " 'اکیلے',\n",
       " 'اگرچہ',\n",
       " 'اہن',\n",
       " 'ایطے',\n",
       " 'ایک',\n",
       " 'ب',\n",
       " 'ت',\n",
       " 'تبزٍ',\n",
       " 'تت',\n",
       " 'تر',\n",
       " 'ترتیت',\n",
       " 'تریي',\n",
       " 'تعذاد',\n",
       " 'تن',\n",
       " 'تو',\n",
       " 'توبم',\n",
       " 'توہی',\n",
       " 'توہیں',\n",
       " 'تٌہب',\n",
       " 'تک',\n",
       " 'تھب',\n",
       " 'تھوڑا',\n",
       " 'تھوڑی',\n",
       " 'تھوڑے',\n",
       " 'تھی',\n",
       " 'تھے',\n",
       " 'تیي',\n",
       " 'ثب',\n",
       " 'ثبئیں',\n",
       " 'ثبترتیت',\n",
       " 'ثبری',\n",
       " 'ثبرے',\n",
       " 'ثبعث',\n",
       " 'ثبلا',\n",
       " 'ثبلترتیت',\n",
       " 'ثبہر',\n",
       " 'ثدبئے',\n",
       " 'ثرآں',\n",
       " 'ثراں',\n",
       " 'ثرش',\n",
       " 'ثعذ',\n",
       " 'ثغیر',\n",
       " 'ثلٌذ',\n",
       " 'ثلٌذوثبلا',\n",
       " 'ثلکہ',\n",
       " 'ثي',\n",
       " 'ثٌب',\n",
       " 'ثٌبرہب',\n",
       " 'ثٌبرہی',\n",
       " 'ثٌبرہے',\n",
       " 'ثٌبًب',\n",
       " 'ثٌذ',\n",
       " 'ثٌذکرو',\n",
       " 'ثٌذکرًب',\n",
       " 'ثٌذی',\n",
       " 'ثڑا',\n",
       " 'ثڑوں',\n",
       " 'ثڑی',\n",
       " 'ثڑے',\n",
       " 'ثھر',\n",
       " 'ثھرا',\n",
       " 'ثھراہوا',\n",
       " 'ثھرپور',\n",
       " 'ثھی',\n",
       " 'ثہت',\n",
       " 'ثہتر',\n",
       " 'ثہتری',\n",
       " 'ثہتریي',\n",
       " 'ثیچ',\n",
       " 'ج',\n",
       " 'خب',\n",
       " 'خبرہب',\n",
       " 'خبرہی',\n",
       " 'خبرہے',\n",
       " 'خبهوظ',\n",
       " 'خبًب',\n",
       " 'خبًتب',\n",
       " 'خبًتی',\n",
       " 'خبًتے',\n",
       " 'خبًٌب',\n",
       " 'خت',\n",
       " 'ختن',\n",
       " 'خجکہ',\n",
       " 'خص',\n",
       " 'خططرذ',\n",
       " 'خلذی',\n",
       " 'خو',\n",
       " 'خواى',\n",
       " 'خوًہی',\n",
       " 'خوکہ',\n",
       " 'خٌبة',\n",
       " 'خگہ',\n",
       " 'خگہوں',\n",
       " 'خگہیں',\n",
       " 'خیطب',\n",
       " 'خیطبکہ',\n",
       " 'در',\n",
       " 'درخبت',\n",
       " 'درخہ',\n",
       " 'درخے',\n",
       " 'درزقیقت',\n",
       " 'درضت',\n",
       " 'دش',\n",
       " 'دفعہ',\n",
       " 'دلچطپ',\n",
       " 'دلچطپی',\n",
       " 'دلچطپیبں',\n",
       " 'دو',\n",
       " 'دور',\n",
       " 'دوراى',\n",
       " 'دوضرا',\n",
       " 'دوضروں',\n",
       " 'دوضری',\n",
       " 'دوضرے',\n",
       " 'دوًوں',\n",
       " 'دکھبئیں',\n",
       " 'دکھبتب',\n",
       " 'دکھبتی',\n",
       " 'دکھبتے',\n",
       " 'دکھبو',\n",
       " 'دکھبًب',\n",
       " 'دکھبیب',\n",
       " 'دی',\n",
       " 'دیب',\n",
       " 'دیتب',\n",
       " 'دیتی',\n",
       " 'دیتے',\n",
       " 'دیر',\n",
       " 'دیٌب',\n",
       " 'دیکھو',\n",
       " 'دیکھٌب',\n",
       " 'دیکھی',\n",
       " 'دیکھیں',\n",
       " 'دے',\n",
       " 'ر',\n",
       " 'راضتوں',\n",
       " 'راضتہ',\n",
       " 'راضتے',\n",
       " 'رریعہ',\n",
       " 'رریعے',\n",
       " 'رکي',\n",
       " 'رکھ',\n",
       " 'رکھب',\n",
       " 'رکھتب',\n",
       " 'رکھتبہوں',\n",
       " 'رکھتی',\n",
       " 'رکھتے',\n",
       " 'رکھی',\n",
       " 'رکھے',\n",
       " 'رہب',\n",
       " 'رہی',\n",
       " 'رہے',\n",
       " 'ز',\n",
       " 'زبصل',\n",
       " 'زبضر',\n",
       " 'زبل',\n",
       " 'زبلات',\n",
       " 'زبلیہ',\n",
       " 'زصوں',\n",
       " 'زصہ',\n",
       " 'زصے',\n",
       " 'زقبئق',\n",
       " 'زقیتیں',\n",
       " 'زقیقت',\n",
       " 'زکن',\n",
       " 'زکویہ',\n",
       " 'زیبدٍ',\n",
       " 'صبف',\n",
       " 'صسیر',\n",
       " 'صفر',\n",
       " 'صورت',\n",
       " 'صورتسبل',\n",
       " 'صورتوں',\n",
       " 'صورتیں',\n",
       " 'ض',\n",
       " 'ضبت',\n",
       " 'ضبتھ',\n",
       " 'ضبدٍ',\n",
       " 'ضبرا',\n",
       " 'ضبرے',\n",
       " 'ضبل',\n",
       " 'ضبلوں',\n",
       " 'ضت',\n",
       " 'ضرور',\n",
       " 'ضرورت',\n",
       " 'ضروری',\n",
       " 'ضلطلہ',\n",
       " 'ضوچ',\n",
       " 'ضوچب',\n",
       " 'ضوچتب',\n",
       " 'ضوچتی',\n",
       " 'ضوچتے',\n",
       " 'ضوچو',\n",
       " 'ضوچٌب',\n",
       " 'ضوچی',\n",
       " 'ضوچیں',\n",
       " 'ضکب',\n",
       " 'ضکتب',\n",
       " 'ضکتی',\n",
       " 'ضکتے',\n",
       " 'ضکٌب',\n",
       " 'ضکی',\n",
       " 'ضکے',\n",
       " 'ضیذھب',\n",
       " 'ضیذھی',\n",
       " 'ضیذھے',\n",
       " 'ضیکٌڈ',\n",
       " 'ضے',\n",
       " 'طرف',\n",
       " 'طریق',\n",
       " 'طریقوں',\n",
       " 'طریقہ',\n",
       " 'طریقے',\n",
       " 'طور',\n",
       " 'طورپر',\n",
       " 'ظبہر',\n",
       " 'ع',\n",
       " 'عذد',\n",
       " 'عظین',\n",
       " 'علاقوں',\n",
       " 'علاقہ',\n",
       " 'علاقے',\n",
       " 'علاوٍ',\n",
       " 'عووهی',\n",
       " 'غبیذ',\n",
       " 'غخص',\n",
       " 'غذ',\n",
       " 'غروع',\n",
       " 'غروعبت',\n",
       " 'غے',\n",
       " 'فرد',\n",
       " 'فی',\n",
       " 'ق',\n",
       " 'قجل',\n",
       " 'قجیلہ',\n",
       " 'قطن',\n",
       " 'لئے',\n",
       " 'لا',\n",
       " 'لازهی',\n",
       " 'لو',\n",
       " 'لوجب',\n",
       " 'لوجی',\n",
       " 'لوجے',\n",
       " 'لوسبت',\n",
       " 'لوسہ',\n",
       " 'لوگ',\n",
       " 'لوگوں',\n",
       " 'لڑکپي',\n",
       " 'لگتب',\n",
       " 'لگتی',\n",
       " 'لگتے',\n",
       " 'لگٌب',\n",
       " 'لگی',\n",
       " 'لگیں',\n",
       " 'لگے',\n",
       " 'لی',\n",
       " 'لیب',\n",
       " 'لیٌب',\n",
       " 'لیں',\n",
       " 'لے',\n",
       " 'ه',\n",
       " 'هتعلق',\n",
       " 'هختلف',\n",
       " 'هسترم',\n",
       " 'هسترهہ',\n",
       " 'هسطوش',\n",
       " 'هسیذ',\n",
       " 'هطئلہ',\n",
       " 'هطئلے',\n",
       " 'هطبئل',\n",
       " 'هطتعول',\n",
       " 'هطلق',\n",
       " 'هعلوم',\n",
       " 'هػتول',\n",
       " 'هلا',\n",
       " 'هوکي',\n",
       " 'هوکٌبت',\n",
       " 'هوکٌہ',\n",
       " 'هٌبضت',\n",
       " 'هڑا',\n",
       " 'هڑًب',\n",
       " 'هڑے',\n",
       " 'هکول',\n",
       " 'هگر',\n",
       " 'هہرثبى',\n",
       " 'هیرا',\n",
       " 'هیری',\n",
       " 'هیرے',\n",
       " 'هیں',\n",
       " 'و',\n",
       " 'وار',\n",
       " 'والے',\n",
       " 'وٍ',\n",
       " 'ًئی',\n",
       " 'ًئے',\n",
       " 'ًب',\n",
       " 'ًبپطٌذ',\n",
       " 'ًبگسیر',\n",
       " 'ًطجت',\n",
       " 'ًقطہ',\n",
       " 'ًو',\n",
       " 'ًوخواى',\n",
       " 'ًکبلٌب',\n",
       " 'ًکتہ',\n",
       " 'ًہ',\n",
       " 'ًہیں',\n",
       " 'ًیب',\n",
       " 'ًے',\n",
       " 'ٓ آش',\n",
       " 'ٹھیک',\n",
       " 'پبئے',\n",
       " 'پبش',\n",
       " 'پبًب',\n",
       " 'پبًچ',\n",
       " 'پر',\n",
       " 'پراًب',\n",
       " 'پطٌذ',\n",
       " 'پل',\n",
       " 'پورا',\n",
       " 'پوچھب',\n",
       " 'پوچھتب',\n",
       " 'پوچھتی',\n",
       " 'پوچھتے',\n",
       " 'پوچھو',\n",
       " 'پوچھوں',\n",
       " 'پوچھٌب',\n",
       " 'پوچھیں',\n",
       " 'پچھلا',\n",
       " 'پھر',\n",
       " 'پہلا',\n",
       " 'پہلی',\n",
       " 'پہلےضی',\n",
       " 'پہلےضے',\n",
       " 'پہلےضےہی',\n",
       " 'پیع',\n",
       " 'چبر',\n",
       " 'چبہب',\n",
       " 'چبہٌب',\n",
       " 'چبہے',\n",
       " 'چلا',\n",
       " 'چلو',\n",
       " 'چلیں',\n",
       " 'چلے',\n",
       " 'چکب',\n",
       " 'چکی',\n",
       " 'چکیں',\n",
       " 'چکے',\n",
       " 'چھوٹب',\n",
       " 'چھوٹوں',\n",
       " 'چھوٹی',\n",
       " 'چھوٹے',\n",
       " 'چھہ',\n",
       " 'چیسیں',\n",
       " 'ڈھوًڈا',\n",
       " 'ڈھوًڈلیب',\n",
       " 'ڈھوًڈو',\n",
       " 'ڈھوًڈًب',\n",
       " 'ڈھوًڈی',\n",
       " 'ڈھوًڈیں',\n",
       " 'ک',\n",
       " 'کئی',\n",
       " 'کئے',\n",
       " 'کب',\n",
       " 'کبفی',\n",
       " 'کبم',\n",
       " 'کت',\n",
       " 'کجھی',\n",
       " 'کرا',\n",
       " 'کرتب',\n",
       " 'کرتبہوں',\n",
       " 'کرتی',\n",
       " 'کرتے',\n",
       " 'کرتےہو',\n",
       " 'کررہب',\n",
       " 'کررہی',\n",
       " 'کررہے',\n",
       " 'کرو',\n",
       " 'کرًب',\n",
       " 'کریں',\n",
       " 'کرے',\n",
       " 'کطی',\n",
       " 'کل',\n",
       " 'کن',\n",
       " 'کوئی',\n",
       " 'کوتر',\n",
       " 'کورا',\n",
       " 'کوروں',\n",
       " 'کورٍ',\n",
       " 'کورے',\n",
       " 'کوطي',\n",
       " 'کوى',\n",
       " 'کوًطب',\n",
       " 'کوًطی',\n",
       " 'کوًطے',\n",
       " 'کھولا',\n",
       " 'کھولو',\n",
       " 'کھولٌب',\n",
       " 'کھولی',\n",
       " 'کھولیں',\n",
       " 'کھولے',\n",
       " 'کہ',\n",
       " 'کہب',\n",
       " 'کہتب',\n",
       " 'کہتی',\n",
       " 'کہتے',\n",
       " 'کہو',\n",
       " 'کہوں',\n",
       " 'کہٌب',\n",
       " 'کہی',\n",
       " 'کہیں',\n",
       " 'کہے',\n",
       " 'کی',\n",
       " 'کیب',\n",
       " 'کیطب',\n",
       " 'کیطرف',\n",
       " 'کیطے',\n",
       " 'کیلئے',\n",
       " 'کیوًکہ',\n",
       " 'کیوں',\n",
       " 'کیے',\n",
       " 'کے',\n",
       " 'کےثعذ',\n",
       " 'کےرریعے',\n",
       " 'گئی',\n",
       " 'گئے',\n",
       " 'گب',\n",
       " 'گرد',\n",
       " 'گروٍ',\n",
       " 'گروپ',\n",
       " 'گروہوں',\n",
       " 'گٌتی',\n",
       " 'گی',\n",
       " 'گیب',\n",
       " 'گے',\n",
       " 'ہر',\n",
       " 'ہن',\n",
       " 'ہو',\n",
       " 'ہوئی',\n",
       " 'ہوئے',\n",
       " 'ہوا',\n",
       " 'ہوبرا',\n",
       " 'ہوبری',\n",
       " 'ہوبرے',\n",
       " 'ہوتب',\n",
       " 'ہوتی',\n",
       " 'ہوتے',\n",
       " 'ہورہب',\n",
       " 'ہورہی',\n",
       " 'ہورہے',\n",
       " 'ہوضکتب',\n",
       " 'ہوضکتی',\n",
       " 'ہوضکتے',\n",
       " 'ہوًب',\n",
       " 'ہوًی',\n",
       " 'ہوًے',\n",
       " 'ہوچکب',\n",
       " 'ہوچکی',\n",
       " 'ہوچکے',\n",
       " 'ہوگئی',\n",
       " 'ہوگئے',\n",
       " 'ہوگیب',\n",
       " 'ہوں',\n",
       " 'ہی',\n",
       " 'ہیں',\n",
       " 'ہے',\n",
       " 'ی',\n",
       " 'یقیٌی',\n",
       " 'یہ',\n",
       " 'یہبں',\n",
       " 'نے',\n",
       " 'ھے',\n",
       " 'ﮨﮯ']"
      ]
     },
     "execution_count": 560,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 560
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Removing Stop Words",
   "id": "d9867f58e9eef0f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-28T19:29:22.597434Z",
     "start_time": "2024-09-28T19:29:22.589940Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def remove_stop_words(text):\n",
    "    text = text.split()\n",
    "    filtered_text = []\n",
    "    for word in text:\n",
    "        if word not in stopWords:\n",
    "            filtered_text.append(word)\n",
    "    return ' '.join(filtered_text)\n",
    "after_stop_wors=remove_stop_words('میں نے ایک  کتاب پڑھی ہے')  # Demo removing stop words\n",
    "print(after_stop_wors)"
   ],
   "id": "d6f556f5a91aa46a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "میں کتاب پڑھی\n"
     ]
    }
   ],
   "execution_count": 561
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-28T19:29:22.990037Z",
     "start_time": "2024-09-28T19:29:22.846871Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data['Tweet']=data['Tweet'].apply(remove_stop_words)\n",
    "data.head() "
   ],
   "id": "91443c105d0c6676",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                               Tweet Class\n",
       "0  میں ایٹم بم بنایا ۔۔۔۔او بھائی ایٹم بمب کوٹ لک...     P\n",
       "1    چندے سے انقلاب عمران خان وزیر اعظم نہیں بن سکتے     N\n",
       "2                           ٹویٹر کا خیال کیسے آیا ؟     O\n",
       "3  سرچ انجن گوگل نائب صدر فضا میں ، 130,000 فٹ بل...     P\n",
       "4           ابھی اسکی لہریں کبھی کبھی آ جاتی یار :أْ     P"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>میں ایٹم بم بنایا ۔۔۔۔او بھائی ایٹم بمب کوٹ لک...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>چندے سے انقلاب عمران خان وزیر اعظم نہیں بن سکتے</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ٹویٹر کا خیال کیسے آیا ؟</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>سرچ انجن گوگل نائب صدر فضا میں ، 130,000 فٹ بل...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ابھی اسکی لہریں کبھی کبھی آ جاتی یار :أْ</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 562,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 562
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Removing URL",
   "id": "3ea28178f20f31e3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-28T19:29:23.128517Z",
     "start_time": "2024-09-28T19:29:23.121347Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import re\n",
    "def remove_url(text):\n",
    "    pattern=re.compile(r'https?://\\S+|www\\.\\S+')   \n",
    "    return pattern.sub(r'', text)\n",
    "\n",
    "after_url=remove_url('میں نے ایک  کتاب پڑھی ہے https://www.google.com')  # Demo removing URL\n",
    "after_url\n",
    "    "
   ],
   "id": "cefcbc5756012305",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'میں نے ایک  کتاب پڑھی ہے '"
      ]
     },
     "execution_count": 563,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 563
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-28T19:29:23.270239Z",
     "start_time": "2024-09-28T19:29:23.256585Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data[\"Tweet\"]=data[\"Tweet\"].apply(remove_url)\n",
    "data.head()"
   ],
   "id": "4d0037b69fe12aa4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                               Tweet Class\n",
       "0  میں ایٹم بم بنایا ۔۔۔۔او بھائی ایٹم بمب کوٹ لک...     P\n",
       "1    چندے سے انقلاب عمران خان وزیر اعظم نہیں بن سکتے     N\n",
       "2                           ٹویٹر کا خیال کیسے آیا ؟     O\n",
       "3  سرچ انجن گوگل نائب صدر فضا میں ، 130,000 فٹ بل...     P\n",
       "4           ابھی اسکی لہریں کبھی کبھی آ جاتی یار :أْ     P"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>میں ایٹم بم بنایا ۔۔۔۔او بھائی ایٹم بمب کوٹ لک...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>چندے سے انقلاب عمران خان وزیر اعظم نہیں بن سکتے</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ٹویٹر کا خیال کیسے آیا ؟</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>سرچ انجن گوگل نائب صدر فضا میں ، 130,000 فٹ بل...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ابھی اسکی لہریں کبھی کبھی آ جاتی یار :أْ</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 564,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 564
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Removing Punctuations",
   "id": "7602ef7a2b5c02b3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-28T19:29:23.410002Z",
     "start_time": "2024-09-28T19:29:23.404441Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import string\n",
    "# got these punctuations from Chatgpt and appended english one's also as some people use those as punc\n",
    "urdu_punctuation = {\n",
    "    \"۔\",  # Full stop (وقفہ)\n",
    "    \"،\",  # Comma (وقفہ)\n",
    "    \"؛\",  # Semicolon (نیم وقفہ)\n",
    "    \":\",  # Colon (دو نقطے)\n",
    "    \"؟\",  # Question mark (سوالیہ نشان)\n",
    "    \"?\",  # Question mark (سوالیہ نشان)\n",
    "    \"!\",  # Exclamation mark (ندائیہ نشان)\n",
    "    \"\\\"\\\"\",  # Quotation marks (اقتباس)\n",
    "    \"''\",  # Single quotes (ایک قوسین)\n",
    "    \"()\",  # Parentheses (قوسین)\n",
    "    \"-\",  # Hyphen (ربط نشان)\n",
    "    \"…\",  # Ellipsis (تین نقطے)\n",
    "    \"/\",  # Slash (سلیش)\n",
    "    \"@\",  # At symbol (ایٹ)\n",
    "    \"#\",  # Hash (ہیش)\n",
    "    \"%\",  # Percentage sign (فیصد)\n",
    "}\n",
    "\n",
    "# Add unique English punctuations\n",
    "urdu_punctuation.update(string.punctuation)\n",
    "\n",
    "new_urdu_punc = ''.join(urdu_punctuation)\n",
    "print(new_urdu_punc)\n"
   ],
   "id": "18cd162757124111",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`+~؟?؛…^\"\"#:)<۔},{.-|[>_]'*''\\/!%،=$()@&\"(;\n"
     ]
    }
   ],
   "execution_count": 565
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-28T19:29:23.558754Z",
     "start_time": "2024-09-28T19:29:23.553050Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def remove_punc(text):\n",
    "    for word in text:\n",
    "        if word in new_urdu_punc:\n",
    "            text = text.replace(word, \"\")\n",
    "    return text\n",
    "\n",
    "after_punc=remove_punc('میں نے- ایک  کتاب? پڑھی>< ہے!')  # Demo removing Punctuation\n",
    "print(after_punc)"
   ],
   "id": "a69208aba28323ad",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "میں نے ایک  کتاب پڑھی ہے\n"
     ]
    }
   ],
   "execution_count": 566
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-28T19:29:23.778846Z",
     "start_time": "2024-09-28T19:29:23.756551Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data[\"Tweet\"]=data[\"Tweet\"].apply(remove_punc)\n",
    "data.head()"
   ],
   "id": "53f1d9f11f507e2d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                               Tweet Class\n",
       "0  میں ایٹم بم بنایا او بھائی ایٹم بمب کوٹ لکھپت ...     P\n",
       "1    چندے سے انقلاب عمران خان وزیر اعظم نہیں بن سکتے     N\n",
       "2                            ٹویٹر کا خیال کیسے آیا      O\n",
       "3  سرچ انجن گوگل نائب صدر فضا میں  130000 فٹ بلند...     P\n",
       "4            ابھی اسکی لہریں کبھی کبھی آ جاتی یار أْ     P"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>میں ایٹم بم بنایا او بھائی ایٹم بمب کوٹ لکھپت ...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>چندے سے انقلاب عمران خان وزیر اعظم نہیں بن سکتے</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ٹویٹر کا خیال کیسے آیا</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>سرچ انجن گوگل نائب صدر فضا میں  130000 فٹ بلند...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ابھی اسکی لہریں کبھی کبھی آ جاتی یار أْ</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 567,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 567
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Removing Emojis\n",
   "id": "10f070c5f5e5e9a7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Removing hashtags",
   "id": "2d4d654a652b19fe"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-28T19:29:23.948233Z",
     "start_time": "2024-09-28T19:29:23.939275Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def remove_hashtags(text):\n",
    "    return re.sub(r'#\\w+', '', text)\n",
    "\n",
    "\n",
    "\n",
    "# Example usage\n",
    "test_hashtags = pd.DataFrame({\n",
    "    'Tweet': [\n",
    "        'یہ ایک #کتاب ہے',  # This is a #book\n",
    "        'آج موسم #خوشگوار ہے',  # The weather is #pleasant today\n",
    "        'مجھے #چائے پسند ہے'  # I like #tea\n",
    "    ],\n",
    "    'Class': ['P', 'N', 'O']\n",
    "})\n",
    "\n",
    "# Apply the function to the 'Tweet' column\n",
    "test_hashtags['Tweet'] = test_hashtags['Tweet'].apply(remove_hashtags)\n",
    "print(test_hashtags)"
   ],
   "id": "1cd9f204212688ce",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Tweet Class\n",
      "0     یہ ایک  ہے     P\n",
      "1    آج موسم  ہے     N\n",
      "2  مجھے  پسند ہے     O\n"
     ]
    }
   ],
   "execution_count": 568
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-28T19:29:24.109909Z",
     "start_time": "2024-09-28T19:29:24.096947Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data[\"Tweet\"]=data[\"Tweet\"].apply(remove_hashtags)\n",
    "data.head()"
   ],
   "id": "861a2da88b063dfd",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                               Tweet Class\n",
       "0  میں ایٹم بم بنایا او بھائی ایٹم بمب کوٹ لکھپت ...     P\n",
       "1    چندے سے انقلاب عمران خان وزیر اعظم نہیں بن سکتے     N\n",
       "2                            ٹویٹر کا خیال کیسے آیا      O\n",
       "3  سرچ انجن گوگل نائب صدر فضا میں  130000 فٹ بلند...     P\n",
       "4            ابھی اسکی لہریں کبھی کبھی آ جاتی یار أْ     P"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>میں ایٹم بم بنایا او بھائی ایٹم بمب کوٹ لکھپت ...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>چندے سے انقلاب عمران خان وزیر اعظم نہیں بن سکتے</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ٹویٹر کا خیال کیسے آیا</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>سرچ انجن گوگل نائب صدر فضا میں  130000 فٹ بلند...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ابھی اسکی لہریں کبھی کبھی آ جاتی یار أْ</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 569,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 569
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Removing short Convo",
   "id": "bbf97d6c89712010"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-28T19:29:24.316367Z",
     "start_time": "2024-09-28T19:29:24.307306Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def remove_short_convo(text):\n",
    "    # Drop rows where the 'Tweet' column has less than 3 words\n",
    "    return text[text['Tweet'].apply(lambda x: len(x.split()) >= 3)]\n",
    "\n",
    "\n",
    "# text['Tweet'].apply(lambda x: len(x.split()) >= 3) applies a lambda function to each element in the 'Tweet' column.\n",
    "# The lambda function returns True if the tweet contains 3 or more words, and False otherwise.\n",
    "# This results in a Series of boolean values.\n",
    "# Apply the Boolean Mask:  \n",
    "# text[text['Tweet'].apply(lambda x: len(x.split()) >= 3)] uses the boolean mask to filter the DataFrame.\n",
    "# Only the rows where the mask is True are selected\n",
    "\n",
    "\n",
    "test_list = pd.DataFrame({\n",
    "    'Tweet': [\n",
    "        'کتاب ہے',  # This is a book\n",
    "        'آج موسم خوشگوار ہے',  # The weather is pleasant today\n",
    "        'مجھے چائے پسند ہے'  # I like tea\n",
    "    ],\n",
    "    'Class': ['P', 'N', 'O']\n",
    "})\n",
    "\n",
    "test_list=remove_short_convo(test_list)\n",
    "print(test_list)"
   ],
   "id": "8979574c30e5888c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Tweet Class\n",
      "1  آج موسم خوشگوار ہے     N\n",
      "2   مجھے چائے پسند ہے     O\n"
     ]
    }
   ],
   "execution_count": 570
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "e20ff6c0c4e1a10a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-28T19:29:24.496389Z",
     "start_time": "2024-09-28T19:29:24.482888Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data=remove_short_convo(data)\n",
    "data.head()"
   ],
   "id": "914931323b8f79b1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                               Tweet Class\n",
       "0  میں ایٹم بم بنایا او بھائی ایٹم بمب کوٹ لکھپت ...     P\n",
       "1    چندے سے انقلاب عمران خان وزیر اعظم نہیں بن سکتے     N\n",
       "2                            ٹویٹر کا خیال کیسے آیا      O\n",
       "3  سرچ انجن گوگل نائب صدر فضا میں  130000 فٹ بلند...     P\n",
       "4            ابھی اسکی لہریں کبھی کبھی آ جاتی یار أْ     P"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>میں ایٹم بم بنایا او بھائی ایٹم بمب کوٹ لکھپت ...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>چندے سے انقلاب عمران خان وزیر اعظم نہیں بن سکتے</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ٹویٹر کا خیال کیسے آیا</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>سرچ انجن گوگل نائب صدر فضا میں  130000 فٹ بلند...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ابھی اسکی لہریں کبھی کبھی آ جاتی یار أْ</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 571,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 571
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Phase 2 - Stemming & Lemmatization",
   "id": "2590766c36674289"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Stemming\n",
   "id": "d5f30edc7b39fcab"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-28T19:29:24.624324Z",
     "start_time": "2024-09-28T19:29:24.616803Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def urdu_stemmer(word):\n",
    "    # List of common prefixes and suffixes in Urdu\n",
    "    prefixes = ['بے', 'نا', 'غیر', 'پرا', 'و', 'ائين', 'تا', 'يان', 'ناك', 'ذو', 'بد','ہم']  # Add more prefixes as needed\n",
    "    suffixes = ['وں', 'یں', 'ا', 'ے', 'ی', 'وا','و', 'ائين', 'تا', 'يان', 'ناك', 'ذو', 'بد' ,'وں']  # Add more suffixes as needed\n",
    "\n",
    "    # Remove prefixes\n",
    "    for prefix in prefixes:\n",
    "        if word.startswith(prefix):\n",
    "            word = word[len(prefix):]\n",
    "            break  # Only remove the first matching prefix\n",
    "\n",
    "    # Remove suffixes\n",
    "    for suffix in suffixes:\n",
    "        if word.endswith(suffix):\n",
    "            word = word[:-len(suffix)]\n",
    "            break  # Only remove the first matching suffix\n",
    "\n",
    "    return word\n",
    "\n",
    "# Example text\n",
    "text = \"\"\"\n",
    " کتابوں غیرمعمولی ناانصافی بےکار خوشیوں غمگین ناگوار \n",
    " پڑھائی خوشبو پراگندہ بےروزگار بےوقوف کتابیں انسانوں \n",
    "ہمراہ بےمعنی بچوں مصیبتوں غیرضروری خوشحال ہمسفر کامیابیاں \n",
    "غیرذمہ دار پریشانیاں زندگی مسائل کامیاب سوالات\n",
    "\"\"\"\n",
    "tokens = text.split()\n",
    "stemmed_tokens = [urdu_stemmer(token) for token in tokens]\n",
    "\n",
    "print(stemmed_tokens)  # Output: ['کتاب']\n"
   ],
   "id": "a6b8a786dc5078",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['کتاب', 'معمول', 'انصاف', 'کار', 'خوشی', 'غمگین', 'گوار', 'پڑھائ', 'خوشب', 'گندہ', 'روزگار', 'وقوف', 'کتاب', 'انسان', 'راہ', 'معن', 'بچ', 'مصیبت', 'ضرور', 'خوشحال', 'سفر', 'کامیابیاں', 'ذمہ', 'دار', 'پریشانیاں', 'زندگ', 'مسائل', 'کامیاب', 'سوالات']\n"
     ]
    }
   ],
   "execution_count": 572
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-28T19:29:24.823293Z",
     "start_time": "2024-09-28T19:29:24.753394Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_stem=data.copy()\n",
    "data_stem['Tweet']=data_stem['Tweet'].apply(lambda x: ' '.join([urdu_stemmer(word) for word in x.split()]))\n",
    "data_stem.head()"
   ],
   "id": "9bc67bea29d72a23",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                               Tweet Class\n",
       "0  م ایٹم بم بنای ا بھائ ایٹم بمب کوٹ لکھپت ال ات...     P\n",
       "1          چند س انقلاب عمران خان زیر اعظم نہ بن سکت     N\n",
       "2                                ٹویٹر ک خیال کیس آی     O\n",
       "3  سرچ انجن گوگل ئب صدر فض م 130000 فٹ بلند چھلان...     P\n",
       "4                   ابھ اسک لہر کبھ کبھ آ جات یار أْ     P"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>م ایٹم بم بنای ا بھائ ایٹم بمب کوٹ لکھپت ال ات...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>چند س انقلاب عمران خان زیر اعظم نہ بن سکت</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ٹویٹر ک خیال کیس آی</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>سرچ انجن گوگل ئب صدر فض م 130000 فٹ بلند چھلان...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ابھ اسک لہر کبھ کبھ آ جات یار أْ</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 573,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 573
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Lemmatization",
   "id": "862125cdd315d482"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-28T19:29:24.945439Z",
     "start_time": "2024-09-28T19:29:24.939845Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Custom lemmatizer example\n",
    "lemmatization_dict = {\n",
    "    'کتابیں': 'کتاب',\n",
    "    'لڑکیاں': 'لڑکی',\n",
    "    # Add more word mappings\n",
    "}\n",
    "\n",
    "def lemmatize(word):\n",
    "    return lemmatization_dict.get(word, word)\n",
    "\n",
    "# Example usage\n",
    "sample_text = \"کتابیں لڑکیاں\"\n",
    "lemmatized_sample = ' '.join([lemmatize(word) for word in sample_text.split()])\n",
    "print(lemmatized_sample)"
   ],
   "id": "f5567c4f5dbb0d9a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "کتاب لڑکی\n"
     ]
    }
   ],
   "execution_count": 574
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Custom dictionary-based lemmatization",
   "id": "6748cca226e36403"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-28T19:29:25.131046Z",
     "start_time": "2024-09-28T19:29:25.112794Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import lemma_dict_file as ldf\n",
    "\n",
    "def lemmatize_urdu(tweets):\n",
    "    lemmatized_text = ' '.join(ldf.urdu_lemma_dict.get(word,word) for word in tweets.split())\n",
    "    return lemmatized_text\n",
    "\n",
    "data_lemmatized = data.copy()\n",
    "data_lemmatized['Tweet'] = data_lemmatized['Tweet'].apply(lemmatize_urdu)\n",
    "data_lemmatized.head()\n",
    "\n",
    "\n"
   ],
   "id": "23c2455ff9e951a8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                               Tweet Class\n",
       "0  میں ایٹم بم بنا او بھائی ایٹم بمب کوٹ لکھپت وا...     P\n",
       "1    چندے سے انقلاب عمران خان وزیر اعظم نہیں بن سکتے     N\n",
       "2                               ٹویٹر کا خیال کیسے آ     O\n",
       "3  سرچ انجن گوگل نائب صدر فضا میں 130000 فٹ بلندی...     P\n",
       "4              ابھی اسکی لہریں کبھی کبھی آ جا یار أْ     P"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>میں ایٹم بم بنا او بھائی ایٹم بمب کوٹ لکھپت وا...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>چندے سے انقلاب عمران خان وزیر اعظم نہیں بن سکتے</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ٹویٹر کا خیال کیسے آ</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>سرچ انجن گوگل نائب صدر فضا میں 130000 فٹ بلندی...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ابھی اسکی لہریں کبھی کبھی آ جا یار أْ</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 575,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 575
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Phase 3 - Feature Extraction",
   "id": "41066cd2bbc108e5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Sample word tokenization",
   "id": "6227985f5520d58a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-28T19:29:25.252700Z",
     "start_time": "2024-09-28T19:29:25.245626Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import  nltk\n",
    "nltk.download('punkt') # for not straight forward languages uses a model to tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "text = \"یہ ایک مثال جملہ ہے۔\"\n",
    "\n",
    "tokenized=word_tokenize(text)\n",
    "print(tokenized)\n",
    "\n"
   ],
   "id": "1f27b6abd5c1cf8e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['یہ', 'ایک', 'مثال', 'جملہ', 'ہے۔']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\abdul\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "execution_count": 576
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-28T19:29:25.516771Z",
     "start_time": "2024-09-28T19:29:25.418621Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# applying on lemmatized\n",
    "data_tokenized = data_lemmatized.copy()\n",
    "\n",
    "data_tokenized['Tweet'] = data_tokenized['Tweet'].apply(word_tokenize)\n",
    "data_tokenized.head()"
   ],
   "id": "85fa9a13c38d9e0c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                               Tweet Class\n",
       "0  [میں, ایٹم, بم, بنا, او, بھائی, ایٹم, بمب, کوٹ...     P\n",
       "1  [چندے, سے, انقلاب, عمران, خان, وزیر, اعظم, نہی...     N\n",
       "2                         [ٹویٹر, کا, خیال, کیسے, آ]     O\n",
       "3  [سرچ, انجن, گوگل, نائب, صدر, فضا, میں, 130000,...     P\n",
       "4    [ابھی, اسکی, لہریں, کبھی, کبھی, آ, جا, یار, أْ]     P"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[میں, ایٹم, بم, بنا, او, بھائی, ایٹم, بمب, کوٹ...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[چندے, سے, انقلاب, عمران, خان, وزیر, اعظم, نہی...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[ٹویٹر, کا, خیال, کیسے, آ]</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[سرچ, انجن, گوگل, نائب, صدر, فضا, میں, 130000,...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[ابھی, اسکی, لہریں, کبھی, کبھی, آ, جا, یار, أْ]</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 577,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 577
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# TF-IDF Vectorization\n",
    "\n"
   ],
   "id": "803988010ca9fe80"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-28T19:29:25.598423Z",
     "start_time": "2024-09-28T19:29:25.592921Z"
    }
   },
   "cell_type": "code",
   "source": "# !pip install scikit-learn",
   "id": "50014c6333f622d",
   "outputs": [],
   "execution_count": 578
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-28T19:29:25.766393Z",
     "start_time": "2024-09-28T19:29:25.683755Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(data_lemmatized['Tweet'])\n",
    "\n",
    "feature_names=tfidf_vectorizer.get_feature_names_out()\n",
    "tfidf_scores=tfidf_matrix.toarray().sum(axis=0)\n",
    "tfidf_df=pd.DataFrame({'Word':feature_names,'TF-IDF':tfidf_scores})\n",
    "tfidf_df=tfidf_df.sort_values('TF-IDF',ascending=False)\n",
    "tfidf_df.head(10)\n"
   ],
   "id": "b4b547234a2a67e7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      Word     TF-IDF\n",
       "3097   میں  37.987015\n",
       "2130    سے  32.446385\n",
       "3847    کا  30.213424\n",
       "3916    کر  25.049767\n",
       "4031    کو  24.150365\n",
       "3243  نہیں  18.251650\n",
       "909    بھی  17.056891\n",
       "1138    جا  15.184444\n",
       "4498    یہ  13.848613\n",
       "3367    وہ  13.799112"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>TF-IDF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3097</th>\n",
       "      <td>میں</td>\n",
       "      <td>37.987015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2130</th>\n",
       "      <td>سے</td>\n",
       "      <td>32.446385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3847</th>\n",
       "      <td>کا</td>\n",
       "      <td>30.213424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3916</th>\n",
       "      <td>کر</td>\n",
       "      <td>25.049767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4031</th>\n",
       "      <td>کو</td>\n",
       "      <td>24.150365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3243</th>\n",
       "      <td>نہیں</td>\n",
       "      <td>18.251650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>909</th>\n",
       "      <td>بھی</td>\n",
       "      <td>17.056891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1138</th>\n",
       "      <td>جا</td>\n",
       "      <td>15.184444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4498</th>\n",
       "      <td>یہ</td>\n",
       "      <td>13.848613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3367</th>\n",
       "      <td>وہ</td>\n",
       "      <td>13.799112</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 579,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 579
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Word2Vec Embeddings\n",
   "id": "2174e5bbc784dc6a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-28T19:29:29.621859Z",
     "start_time": "2024-09-28T19:29:25.894375Z"
    }
   },
   "cell_type": "code",
   "source": [
    "!pip install gensim\n",
    "# !pip install --upgrade numpy"
   ],
   "id": "dad4eb2cf0e89070",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in c:\\users\\abdul\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.3.3)\n",
      "Requirement already satisfied: numpy<2.0,>=1.18.5 in c:\\users\\abdul\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gensim) (1.26.4)\n",
      "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in c:\\users\\abdul\\appdata\\roaming\\python\\python312\\site-packages (from gensim) (1.12.0)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\abdul\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gensim) (7.0.4)\n",
      "Requirement already satisfied: wrapt in c:\\users\\abdul\\appdata\\roaming\\python\\python312\\site-packages (from smart-open>=1.8.1->gensim) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: Loading egg at c:\\users\\abdul\\appdata\\local\\programs\\python\\python312\\lib\\site-packages\\mlrose-1.3.0-py3.12.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\n"
     ]
    }
   ],
   "execution_count": 580
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-28T19:29:29.914443Z",
     "start_time": "2024-09-28T19:29:29.689653Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "model=Word2Vec(data_tokenized['Tweet'],min_count=1,window=5,sg=0,vector_size=10)\n",
    "similar_words = model.wv.most_similar(\"اچھا\", topn=5)\n",
    "similar_df=pd.DataFrame(similar_words,columns=['Word','Similarity'])\n",
    "similar_df\n"
   ],
   "id": "e8d699cd7cd43729",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    Word  Similarity\n",
       "0   جانے    0.920974\n",
       "1  فیروز    0.857997\n",
       "2   دقیق    0.846315\n",
       "3   سوال    0.839393\n",
       "4   بھوک    0.837931"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>جانے</td>\n",
       "      <td>0.920974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>فیروز</td>\n",
       "      <td>0.857997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>دقیق</td>\n",
       "      <td>0.846315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>سوال</td>\n",
       "      <td>0.839393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>بھوک</td>\n",
       "      <td>0.837931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 581,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 581
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Phase 4 - N-Gram Analysis\n",
    "\n"
   ],
   "id": "6e86f051f4035aaf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-28T19:29:30.101979Z",
     "start_time": "2024-09-28T19:29:29.958371Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import  nltk\n",
    "from nltk.util import ngrams\n",
    "from collections import Counter\n",
    "nltk.download('punkt')\n",
    "\n",
    "analysis_data=data.copy()\n",
    "\n",
    "analysis_data[\"Tweet\"]=analysis_data[\"Tweet\"].apply(nltk.word_tokenize)\n",
    "\n",
    "unigrams=[word for tokens in analysis_data[\"Tweet\"] for word in tokens]\n",
    "bigrams=[bigram for tokens in analysis_data[\"Tweet\"] for bigram in ngrams(tokens,2)]\n",
    "trigrams=[trigram for tokens in analysis_data[\"Tweet\"] for trigram in ngrams(tokens,3)]\n",
    "\n",
    "unigram_freq=Counter(unigrams)\n",
    "bigram_freq=Counter(bigrams)\n",
    "trigram_freq=Counter(trigrams)\n",
    "\n",
    "top_10_bigrams =bigram_freq.most_common(10)\n",
    "top_10_trigrams =trigram_freq.most_common(10)\n",
    "\n",
    "print(\"Top 10 Bigrams:\")\n",
    "for bigram, freq in top_10_bigrams:\n",
    "    print(f\"{bigram}: {freq}\")\n",
    "\n",
    "print(\"\\nTop 10 Trigrams:\")\n",
    "for trigram, freq in top_10_trigrams:\n",
    "    print(f\"{trigram}: {freq}\")"
   ],
   "id": "5b8cdfb7bec4d26d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Bigrams:\n",
      "('سے', 'انقلاب'): 26\n",
      "('چندے', 'سے'): 25\n",
      "('عمران', 'خان'): 21\n",
      "('طاہر', 'القادری'): 19\n",
      "('اسلام', 'آباد'): 17\n",
      "('تحریک', 'انصاف'): 14\n",
      "('عوامی', 'تحریک'): 13\n",
      "('سیدنا', 'عمر'): 12\n",
      "('وزیر', 'اعظم'): 11\n",
      "('کا', 'اعلان'): 11\n",
      "\n",
      "Top 10 Trigrams:\n",
      "('چندے', 'سے', 'انقلاب'): 23\n",
      "('ایم', 'کیو', 'ایم'): 10\n",
      "('سیدنا', 'عمر', 'فاروق'): 8\n",
      "('ڈاکٹر', 'طاہر', 'القادری'): 6\n",
      "('نیا', 'اسلامی', 'سال'): 5\n",
      "('اسلامی', 'سال', 'مبارک'): 5\n",
      "('اسلام', 'آباد', 'میں'): 5\n",
      "('ملک', 'بھر', 'میں'): 5\n",
      "('عمر', 'فاروق', 'رضی'): 5\n",
      "('فاروق', 'رضی', 'اللہ'): 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\abdul\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "execution_count": 582
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Phase 5 - Sentiment Analysis",
   "id": "c481dd3c86bd3228"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-28T19:29:30.213904Z",
     "start_time": "2024-09-28T19:29:30.201247Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "print(data.isnull().sum())\n",
    "data = data.dropna()\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data['Tweet'], data['Class'], test_size=0.20, random_state=90)\n",
    "\n",
    "\n",
    "\n",
    "# Assuming tfidf_matrix is already created\n",
    "X_train_tfidf = tfidf_matrix[:len(X_train)] #  This line takes the first len(X_train) rows from tfidf_matrix and assigns them to X_train_tfidf. These rows correspond to the training set features.\n",
    "X_test_tfidf = tfidf_matrix[len(X_train):len(X_train) + len(X_test)] # This line takes the remaining rows from tfidf_matrix (starting from len(X_train) to the end) and assigns them to X_test_tfidf. These rows correspond to the test set features.\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "7c43ee9516a54e24",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet    0\n",
      "Class    1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "execution_count": 583
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Applying Logistic Regression",
   "id": "595c83ce4ab050b7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-28T19:29:30.359260Z",
     "start_time": "2024-09-28T19:29:30.278461Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "model=LogisticRegression()\n",
    "model.fit(X_train_tfidf,y_train)\n",
    "y_pred=model.predict(X_test_tfidf)\n"
   ],
   "id": "7cd6316ad26a5f93",
   "outputs": [],
   "execution_count": 584
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Evaluating the Model",
   "id": "a26450e56b3ba0df"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-28T19:29:30.466136Z",
     "start_time": "2024-09-28T19:29:30.444804Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Calculate accuracy, precision, recall, and F1-score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted',zero_division=0)\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1-score: {f1:.2f}\")"
   ],
   "id": "c38cc05026b1e234",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.53\n",
      "Precision: 0.54\n",
      "Recall: 0.53\n",
      "F1-score: 0.51\n"
     ]
    }
   ],
   "execution_count": 585
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
